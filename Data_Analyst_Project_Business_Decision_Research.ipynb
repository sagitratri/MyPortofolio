{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Data Analyst Project: Business Decision Research",
      "provenance": [],
      "collapsed_sections": [
        "F8lJlRHxCAlG",
        "5chUpSPBCDzi",
        "Z7VQL1f-AMz2"
      ],
      "authorship_tag": "ABX9TyO4BE0BJfpZtQkorZn/7dnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagitratri/MyPortofolio/blob/main/Data_Analyst_Project_Business_Decision_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N1lUlXzZ-xxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Coding Test: Data Preparation"
      ],
      "metadata": {
        "id": "F8lJlRHxCAlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63mu916DYK-5",
        "outputId": "8d9a2ab1-69b5-4476-bd46-e7b9c529660e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lima data teratas:\n",
            "   no  Row_Num  Customer_ID Product  First_Transaction  Last_Transaction  \\\n",
            "0   1        1        29531   Jaket      1466304274396     1538718482608   \n",
            "1   2        2        29531  Sepatu      1406077331494     1545735761270   \n",
            "2   3        3       141526     Tas      1493349147000     1548322802000   \n",
            "3   4        4       141526   Jaket      1493362372547     1547643603911   \n",
            "4   5        5        37545  Sepatu      1429178498531     1542891221530   \n",
            "\n",
            "   Average_Transaction_Amount  Count_Transaction  \n",
            "0                     1467681                 22  \n",
            "1                     1269337                 41  \n",
            "2                      310915                 30  \n",
            "3                      722632                 27  \n",
            "4                     1775036                 25  \n",
            "\n",
            "Info dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 8 columns):\n",
            " #   Column                      Non-Null Count   Dtype \n",
            "---  ------                      --------------   ----- \n",
            " 0   no                          100000 non-null  int64 \n",
            " 1   Row_Num                     100000 non-null  int64 \n",
            " 2   Customer_ID                 100000 non-null  int64 \n",
            " 3   Product                     100000 non-null  object\n",
            " 4   First_Transaction           100000 non-null  int64 \n",
            " 5   Last_Transaction            100000 non-null  int64 \n",
            " 6   Average_Transaction_Amount  100000 non-null  int64 \n",
            " 7   Count_Transaction           100000 non-null  int64 \n",
            "dtypes: int64(7), object(1)\n",
            "memory usage: 6.1+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Importing Data dan Inspection\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv',sep=';')\n",
        "\n",
        "print('Lima data teratas:')\n",
        "print(df.head())\n",
        "\n",
        "print('\\nInfo dataset:')\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleansing\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "\n",
        "# Kolom First_Transaction\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "# Kolom Last_Transaction\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "\n",
        "print('Lima data teratas:')\n",
        "print(df.head())\n",
        "\n",
        "print('\\nInfo dataset:')\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "yi6kTGdP_JFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b635e6b3-e21c-43f5-80a4-6f47e3bd2172"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lima data teratas:\n",
            "   no  Row_Num  Customer_ID Product             First_Transaction  \\\n",
            "0   1        1        29531   Jaket 2016-06-19 02:44:34.396000000   \n",
            "1   2        2        29531  Sepatu 2014-07-23 01:02:11.493999872   \n",
            "2   3        3       141526     Tas 2017-04-28 03:12:27.000000000   \n",
            "3   4        4       141526   Jaket 2017-04-28 06:52:52.546999808   \n",
            "4   5        5        37545  Sepatu 2015-04-16 10:01:38.530999808   \n",
            "\n",
            "               Last_Transaction  Average_Transaction_Amount  Count_Transaction  \n",
            "0 2018-10-05 05:48:02.608000000                     1467681                 22  \n",
            "1 2018-12-25 11:02:41.269999872                     1269337                 41  \n",
            "2 2019-01-24 09:40:02.000000000                      310915                 30  \n",
            "3 2019-01-16 13:00:03.911000064                      722632                 27  \n",
            "4 2018-11-22 12:53:41.529999872                     1775036                 25  \n",
            "\n",
            "Info dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 8 columns):\n",
            " #   Column                      Non-Null Count   Dtype         \n",
            "---  ------                      --------------   -----         \n",
            " 0   no                          100000 non-null  int64         \n",
            " 1   Row_Num                     100000 non-null  int64         \n",
            " 2   Customer_ID                 100000 non-null  int64         \n",
            " 3   Product                     100000 non-null  object        \n",
            " 4   First_Transaction           100000 non-null  datetime64[ns]\n",
            " 5   Last_Transaction            100000 non-null  datetime64[ns]\n",
            " 6   Average_Transaction_Amount  100000 non-null  int64         \n",
            " 7   Count_Transaction           100000 non-null  int64         \n",
            "dtypes: datetime64[ns](2), int64(5), object(1)\n",
            "memory usage: 6.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Churn Customers\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "\n",
        "# Pengecekan transaksaksi terakhir dalam dataset\n",
        "print(max(df['Last_Transaction']))\n",
        "\n",
        "# Klasifikasikan customer yang berstatus churn atau tidak dengan boolean\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "print('Lima data teratas:')\n",
        "print(df.head())\n",
        "\n",
        "print('\\nInfo dataset:')\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEK79i6v-7uq",
        "outputId": "f9661288-4c2c-4be1-f4e5-363e26b1a22d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2019-02-01 23:57:57.286000128\n",
            "Lima data teratas:\n",
            "   no  Row_Num  Customer_ID Product             First_Transaction  \\\n",
            "0   1        1        29531   Jaket 2016-06-19 02:44:34.396000000   \n",
            "1   2        2        29531  Sepatu 2014-07-23 01:02:11.493999872   \n",
            "2   3        3       141526     Tas 2017-04-28 03:12:27.000000000   \n",
            "3   4        4       141526   Jaket 2017-04-28 06:52:52.546999808   \n",
            "4   5        5        37545  Sepatu 2015-04-16 10:01:38.530999808   \n",
            "\n",
            "               Last_Transaction  Average_Transaction_Amount  \\\n",
            "0 2018-10-05 05:48:02.608000000                     1467681   \n",
            "1 2018-12-25 11:02:41.269999872                     1269337   \n",
            "2 2019-01-24 09:40:02.000000000                      310915   \n",
            "3 2019-01-16 13:00:03.911000064                      722632   \n",
            "4 2018-11-22 12:53:41.529999872                     1775036   \n",
            "\n",
            "   Count_Transaction is_churn  \n",
            "0                 22    False  \n",
            "1                 41    False  \n",
            "2                 30    False  \n",
            "3                 27    False  \n",
            "4                 25    False  \n",
            "\n",
            "Info dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 9 columns):\n",
            " #   Column                      Non-Null Count   Dtype         \n",
            "---  ------                      --------------   -----         \n",
            " 0   no                          100000 non-null  int64         \n",
            " 1   Row_Num                     100000 non-null  int64         \n",
            " 2   Customer_ID                 100000 non-null  int64         \n",
            " 3   Product                     100000 non-null  object        \n",
            " 4   First_Transaction           100000 non-null  datetime64[ns]\n",
            " 5   Last_Transaction            100000 non-null  datetime64[ns]\n",
            " 6   Average_Transaction_Amount  100000 non-null  int64         \n",
            " 7   Count_Transaction           100000 non-null  int64         \n",
            " 8   is_churn                    100000 non-null  object        \n",
            "dtypes: datetime64[ns](2), int64(5), object(2)\n",
            "memory usage: 6.9+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus kolom yang tidak diperlukan\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "\n",
        "# Hapus kolom-kolom yang tidak diperlukan\n",
        "del df['no']\n",
        "del df['Row_Num']\n",
        "\n",
        "# Cetak lima data teratas\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "eQRmLMce_3ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Coding Test: Data Visualization\n"
      ],
      "metadata": {
        "id": "5chUpSPBCDzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customer acquisition by year\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Kolom tahun transaksi pertama\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "# Kolom tahun transaksi terakhir\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "\n",
        "df_year = df.groupby(['Year_First_Transaction'])['Customer_ID'].count()\n",
        "df_year.plot(x='Year_First_Transaction', y='Customer_ID', kind='bar', title='Graph of Customer Acquisition')\n",
        "plt.xlabel('Year_First_Transaction')\n",
        "plt.ylabel('Num_of_Customer')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLVyoa8sCIBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transaction by year\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.clf()\n",
        "df_year = df.groupby(['Year_First_Transaction'])['Count_Transaction'].sum()\n",
        "df_year.plot(x='Year_First_Transaction', y='Count_Transaction', kind='bar', title='Graph of Transaction Customer')\n",
        "plt.xlabel('Year_First_Transaction')\n",
        "plt.ylabel('Num_of_Transaction')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n_GW3ovbN3QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average transaction amount by year\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.clf()\n",
        "sns.pointplot(data = df.groupby(['Product', 'Year_First_Transaction']).mean().reset_index(), \n",
        "              x='Year_First_Transaction', \n",
        "              y='Average_Transaction_Amount', \n",
        "              hue='Product')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YD1KNA79ZmCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proporsi churned customer untuk setiap produk\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.clf()\n",
        "# Melakukan pivot data dengan pivot_table\n",
        "df_piv = df.pivot_table(index='is_churn', \n",
        "                        columns='Product',\n",
        "                        values='Customer_ID', \n",
        "                        aggfunc='count', \n",
        "                        fill_value=0)\n",
        "# Mendapatkan Proportion Churn by Product\n",
        "plot_product = df_piv.count().sort_values(ascending=False).head(5).index\n",
        "# Plot pie chartnya\n",
        "df_piv = df_piv.reindex(columns=plot_product)\n",
        "df_piv.plot.pie(subplots=True,\n",
        "                figsize=(10, 7),\n",
        "                layout=(-1, 2),\n",
        "                autopct='%1.0f%%',\n",
        "                title='Proportion Churn by Product')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "62MKavU-pgHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribusi kategorisasi count transaction\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.clf()\n",
        "# Kategorisasi jumlah transaksi\n",
        "def func(row):\n",
        "    if row['Count_Transaction'] == 1:\n",
        "        val = '1. 1'\n",
        "    elif (row['Count_Transaction'] > 1 and row['Count_Transaction'] <= 3):\n",
        "        val ='2.2 - 3'\n",
        "    elif (row['Count_Transaction'] > 3 and row['Count_Transaction'] <= 6):\n",
        "        val ='3.4 - 6'\n",
        "    elif (row['Count_Transaction'] > 6 and row['Count_Transaction'] <= 10):\n",
        "        val ='4.7 - 10'\n",
        "    else:\n",
        "        val ='5. > 10'\n",
        "    return val\n",
        "# Tambahkan kolom baru\n",
        "df['Count_Transaction_Group'] = df.apply(func, axis=1)\n",
        "\n",
        "df_year = df.groupby(['Count_Transaction_Group'])['Customer_ID'].count()\n",
        "df_year.plot(x='Count_Transaction_Group', y='Customer_ID', kind='bar', title='Customer Distribution by Count Transaction Group')\n",
        "plt.xlabel('Count_Transaction_Group')\n",
        "plt.ylabel('Num_of_Customer')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DOVzbe5syKGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribusi kategorisasi average transaction amount\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.clf()\n",
        "# Kategorisasi rata-rata besar transaksi\n",
        "def f(row):\n",
        "    if (row['Average_Transaction_Amount'] >= 100000 and row['Average_Transaction_Amount'] <= 250000):\n",
        "        val ='1. 100.000 - 250.000'\n",
        "    elif (row['Average_Transaction_Amount'] > 250000 and row['Average_Transaction_Amount'] <= 500000):\n",
        "        val ='2. >250.000 - 500.000'\n",
        "    elif (row['Average_Transaction_Amount'] > 500000 and row['Average_Transaction_Amount'] <= 750000):\n",
        "        val ='3. >500.000 - 750.000'\n",
        "    elif (row['Average_Transaction_Amount'] > 750000 and row['Average_Transaction_Amount'] <= 1000000):\n",
        "        val ='4. >750.000 - 1.000.000'\n",
        "    elif (row['Average_Transaction_Amount'] > 1000000 and row['Average_Transaction_Amount'] <= 2500000):\n",
        "        val ='5. >1.000.000 - 2.500.000'\n",
        "    elif (row['Average_Transaction_Amount'] > 2500000 and row['Average_Transaction_Amount'] <= 5000000):\n",
        "        val ='6. >2.500.000 - 5.000.000'\n",
        "    elif (row['Average_Transaction_Amount'] > 5000000 and row['Average_Transaction_Amount'] <= 10000000):\n",
        "        val ='7. >5.000.000 - 10.000.000'\n",
        "    else:\n",
        "        val ='8. >10.000.000'\n",
        "    return val\n",
        "# Tambahkan kolom baru\n",
        "df['Average_Transaction_Amount_Group'] = df.apply(f, axis=1)\n",
        "\n",
        "df_year = df.groupby(['Average_Transaction_Amount_Group'])['Customer_ID'].count()\n",
        "df_year.plot(x='Average_Transaction_Amount_Group', y='Customer_ID', kind='bar', title='Customer Distribution by Average Transaction Amount Group')\n",
        "plt.xlabel('Average_Transaction_Amount_Group')\n",
        "plt.ylabel('Num_of_Customer')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RD5vgJXY-855"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Coding Test : Modelling"
      ],
      "metadata": {
        "id": "Z7VQL1f-AMz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Columns dan Target\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "# Feature column: Year_Diff\n",
        "df['Year_Diff'] = df['Year_Last_Transaction'] - df['Year_First_Transaction']\n",
        "\n",
        "# Nama-nama feature columns\n",
        "feature_columns = ['Average_Transaction_Amount', 'Count_Transaction', 'Year_Diff']\n",
        "\n",
        "# Features variable\n",
        "X = df[feature_columns] \n",
        "\n",
        "# Target variable\n",
        "y = df['is_churn'] "
      ],
      "metadata": {
        "id": "g3jM7ZZdANzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split X dan y ke dalam bagian training dan testing\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "df['Year_Diff']=df['Year_Last_Transaction']-df['Year_First_Transaction']\n",
        "feature_columns = ['Average_Transaction_Amount', 'Count_Transaction', 'Year_Diff']\n",
        "\n",
        "X = df[feature_columns] \n",
        "y = df['is_churn']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state= 0)"
      ],
      "metadata": {
        "id": "svwrU-WoBt8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train, predict dan evaluate\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "df['Year_Diff']=df['Year_Last_Transaction']-df['Year_First_Transaction']\n",
        "feature_columns = ['Average_Transaction_Amount', 'Count_Transaction', 'Year_Diff']\n",
        "\n",
        "X = df[feature_columns] \n",
        "y = df['is_churn'] \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Inisiasi model logreg\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict model\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluasi model menggunakan confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:\\n', cnf_matrix)"
      ],
      "metadata": {
        "id": "JeQJqFSmC2i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualisasi Confusion Matrix\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "df['Year_Diff']=df['Year_Last_Transaction']-df['Year_First_Transaction']\n",
        "feature_columns = ['Average_Transaction_Amount', 'Count_Transaction', 'Year_Diff']\n",
        "\n",
        "X = df[feature_columns] \n",
        "y = df['is_churn'] \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# import required modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.clf()\n",
        "# name  of classes\n",
        "class_names = [0, 1] \n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap='YlGnBu', fmt='g')\n",
        "ax.xaxis.set_label_position('top')\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dZf8j-ANEec4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy, Precision, dan Recall\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/data_retail.csv', sep=';')\n",
        "df['First_Transaction'] = pd.to_datetime(df['First_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Last_Transaction'] = pd.to_datetime(df['Last_Transaction']/1000, unit='s', origin='1970-01-01')\n",
        "df['Year_First_Transaction'] = df['First_Transaction'].dt.year\n",
        "df['Year_Last_Transaction'] = df['Last_Transaction'].dt.year\n",
        "df.loc[df['Last_Transaction'] <= '2018-08-01', 'is_churn'] = True \n",
        "df.loc[df['Last_Transaction'] > '2018-08-01', 'is_churn'] = False \n",
        "\n",
        "df['Year_Diff']=df['Year_Last_Transaction']-df['Year_First_Transaction']\n",
        "feature_columns = ['Average_Transaction_Amount', 'Count_Transaction', 'Year_Diff']\n",
        "\n",
        "X = df[feature_columns] \n",
        "y = df['is_churn'] \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "#Menghitung Accuracy, Precision, dan Recall\n",
        "print('Accuracy :', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred, average='micro'))\n",
        "print('Recall   :', recall_score(y_test, y_pred, average='micro'))"
      ],
      "metadata": {
        "id": "glKROl-EG9s7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}